{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCZaTk6POkXF"
      },
      "source": [
        "# Problem Formulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG7iwHNbO_HM"
      },
      "source": [
        "### What is the input?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI3RWLu5POXz"
      },
      "source": [
        "the input data is a graph that represent chemical compound ðŸ’Š \n",
        "\n",
        "*   The atoms of the chemical compound representing nodes and bonds as edges\n",
        "*   It is a bioassay task for anticancer activity prediction\n",
        "*   this dataset is very unbalanced ðŸ˜ž\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh4P8Pf2RtC7"
      },
      "source": [
        "### What is the output?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfogqJlZSBOO"
      },
      "source": [
        "The main output is the label of anticancer activity prediction task ðŸ”¥\n",
        "\n",
        "\n",
        "*   the label represent if the chemical compound is positive against non-small cell lung cancer, or negative:\n",
        "  - 1 for possitive\n",
        "  - 0 for negative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V88cNuLOSp7e"
      },
      "source": [
        "### What data mining function is required?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7P-930fTHrI"
      },
      "source": [
        "As I understand from this part of the slide\n",
        "\n",
        "\n",
        "```\n",
        "Data Mining Functions\n",
        "1. Generalization and Summarization\n",
        "2. Association and Correlation\n",
        "3. Classification & Prediction\n",
        "4. Clustering\n",
        "5. Outlier/Anomaly Analysis\n",
        "6. Time and Ordering \n",
        "7. Structure and Network Analysis\n",
        "```\n",
        "\n",
        "The data mining in this problem requires Classification & Prediction After cleaning the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cNfm22JTIs9"
      },
      "source": [
        "### What could be the challenges?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgXlNDGyTPEt"
      },
      "source": [
        "The Challenges represented in:\n",
        "\n",
        "\n",
        "*   Reading SDF format of the files that contain data\n",
        "*   Dealing with graphs\n",
        "*   Unbalanced data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUrv-fxXTPWj"
      },
      "source": [
        "### What is the impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPmpbe4wTYUz"
      },
      "source": [
        "The impact of using the raw data as it is, without cleaning and reprocessing, will result a model with low accuracy that doesn't learn well or a desired from the data in the traing stage\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The real-life impact of building a model that solve this problem is represent in finding the appropriate chemical compound that could treat lung cancer patients by distinguish if the chemical compound is positive against non-small cell lung cancer, or negative ðŸ”¥ðŸ”¥ðŸ”¥\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "Solving this problem could provide a solution for cancer patients ðŸ˜!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yjhAPTaTYgP"
      },
      "source": [
        "### What is an ideal solution?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smtxsp6rTe6q"
      },
      "source": [
        "the ideal solution is to clean and preprocess the data before working with it\n",
        "\n",
        "\n",
        "\n",
        "> Some of the possible solutions are:\n",
        "\n",
        "\n",
        "\n",
        "*   Dealing with unbalanced data by up-sampling it\n",
        "*   Preprocess text data (that represent the atom name in the chemical compound) before dealing with them\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzijuPO0fkKC"
      },
      "source": [
        "### What is the experimental protocol used and how was it carried out? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t0TqNx_fqp3"
      },
      "source": [
        "After loading the data and cleaning and preprocessing it, the experimental protocol used is spliting the training dataset into training_set and validation_set to fit the model using the new training_set and measure the perormance (AUROC) of the model using the validation_set and then make the prediction by using the original test dataset ðŸ”¥\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qo-uOPBfrje"
      },
      "source": [
        "### What preprocessing steps are used?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZW8oroKfysp"
      },
      "source": [
        "*   view the data and understand it\n",
        "*   adjust the training data to ***up-sample*** the positive class samples\n",
        "*   preprocess text data through:\n",
        "  -   build vocabulary from training set using tokenizer\n",
        "  -   apply pad_sequences() function \n",
        "*   apply prepare_single_batch for all samples in gen_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hzdweU6Bh7i"
      },
      "source": [
        "# Get Started (Importing packages & Loading the data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XrzCH4z6_ss"
      },
      "source": [
        "## Import packages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WkKhg1LT5mqX"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_score, recall_score, f1_score, precision_recall_curve\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import math\n",
        "sns.set()\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from time import time\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KlsZO5BCVyGz"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample \n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8qm-scQTor61"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten, Dropout\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZslYa433nV4c",
        "outputId": "bd046020-d0ed-4f22-b729-c0422dc86c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54 kB 1.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73 kB 1.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 346 kB 5.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134 kB 51.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 47.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462 kB 62.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79 kB 6.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 178 kB 26.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.6 MB 44.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85 kB 3.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41 kB 272 kB/s \n",
            "\u001b[?25h  Building wheel for tf2-gnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet tf2_gnn\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput\n",
        "from tf2_gnn.layers.message_passing import GNN_Edge_MLP, GNN_FiLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H3juXRr_7UQj"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yoY2ymc4PyaA"
      },
      "outputs": [],
      "source": [
        "# some seeting for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZOszu8Y7p1k"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lHGrifgKB_4b"
      },
      "outputs": [],
      "source": [
        "# create function that read sdf files\n",
        "\n",
        "def read_sdf(file):\n",
        "    with open(file, 'r') as rf:\n",
        "        content = rf.read()\n",
        "    samples = content.split('$$$$')\n",
        "    \n",
        "    def parse_sample(s):\n",
        "        lines = s.splitlines()\n",
        "        links = []\n",
        "        nodes = []\n",
        "        label = 0\n",
        "        for l in lines:\n",
        "            if l.strip() == '1.0':\n",
        "                label = 1\n",
        "            if l.strip() == '-1.0':\n",
        "                label = 0\n",
        "            if l.startswith('    '):\n",
        "                feature = l.split()\n",
        "                node = feature[3]\n",
        "                nodes.append(node)\n",
        "            elif l.startswith(' '):\n",
        "                lnk = l.split()\n",
        "                # edge: (from, to,) (1-based index)\n",
        "                if int(lnk[0]) - 1 < len(nodes):\n",
        "                    links.append((\n",
        "                        int(lnk[0])-1, \n",
        "                        int(lnk[1])-1, # zero-based index\n",
        "                        # int(lnk[2]) ignore edge weight\n",
        "                    ))\n",
        "        return nodes, np.array(links), label\n",
        "    \n",
        "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "9245a1d13a51458683fb8919859286eb",
            "a1f9f23283d04df9bab7e503d4a009e2",
            "0807ef1d5bef440eab026169de642297",
            "53646c4ab376433a93fd7902a2cc0b12",
            "ba2e795d935147b0b1f35aedc4671d92",
            "aaec8ff6a4664d38b1be547dbb22893f",
            "e43833dbdaf148b19d81bc305daaccf8",
            "17d34751168445faa03fdcfeac1eff83",
            "add0bed843aa4ba8be6f413d7b23a213",
            "f740669a2ea240c99f187d45e698ae9c",
            "6fbd187abf854d948f3d8af7313c2be6",
            "0564a0534bd348919b2d449d4c75f4d9",
            "6b8cdb85a7a84fbca48633f233bb00df",
            "610f674723db47dfa53dbc08a96cee05",
            "45ca81f6d35f46608cd622a5db8a2dd2",
            "7070e68979674461b7640e18d2b7aac4",
            "65ee1c3638af49b894d3fbce6865cb73",
            "ccb6c86d21e6451797ff23f7c60703e5",
            "344f757c297f4dec8643515679b98bd7",
            "c9189dbddec2457ea52f32f945e3af38",
            "95e90162bf3045ccbde21a72b873c1a1",
            "a4314f4295074f809549b59c68841ba5"
          ]
        },
        "id": "GxAKKxHY7voE",
        "outputId": "d9927037-f68c-4eee-9f22-fdf7439187b5"
      },
      "outputs": [],
      "source": [
        "# Loading the data from csv files\n",
        "\n",
        "train = read_sdf('data/train.sdf')\n",
        "test = read_sdf('data/test_x.sdf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ6A7dMT7wh0",
        "outputId": "39779afa-d6fc-4fa1-efd4-b187699a38b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['S', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0,  8],\n",
            "       [ 0, 14],\n",
            "       [ 1, 10],\n",
            "       [ 2, 11],\n",
            "       [ 3,  7],\n",
            "       [ 4,  7],\n",
            "       [ 5,  9],\n",
            "       [ 5, 14],\n",
            "       [ 6, 14],\n",
            "       [ 6, 17],\n",
            "       [ 7, 22],\n",
            "       [ 8,  9],\n",
            "       [ 8, 10],\n",
            "       [ 9, 11],\n",
            "       [10, 12],\n",
            "       [11, 13],\n",
            "       [12, 13],\n",
            "       [12, 15],\n",
            "       [13, 16],\n",
            "       [15, 18],\n",
            "       [16, 19],\n",
            "       [17, 20],\n",
            "       [17, 21],\n",
            "       [18, 19],\n",
            "       [20, 23],\n",
            "       [21, 24],\n",
            "       [22, 23],\n",
            "       [22, 24]]), 0)\n"
          ]
        }
      ],
      "source": [
        "# Look at first records of the data \n",
        "print(train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNRkgHlk0NBM"
      },
      "source": [
        "## Data Up-Sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZynBbx-0wfE",
        "outputId": "f88d4c44-9824-434c-b7c1-88bb57f22f2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1], dtype=object), array([23806,  1218]))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(np.array(train)[:,2],return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3q6plZxU0UY0"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame(train, columns=['node','edge','label']) # convert train into DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRolmGWX1I2F",
        "outputId": "43a53a93-6b2a-4103-e622-95c6ac1c0fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    23806\n",
            "1     1218\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# print the count of 0,1 in the label column\n",
        "print(train_df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hX1IwNO61Iy6"
      },
      "outputs": [],
      "source": [
        "class_0 = train_df[train_df['label'] == 0] # get all data that belong to negative class (label = 0) \n",
        "class_1 = train_df[train_df['label'] == 1] # get all data that belong to possitive class (label = 1) \n",
        "\n",
        "class_1 = resample(class_1, replace=True, n_samples=len(class_0), random_state=42)  # resample class_1\n",
        "upsampled_data = pd.concat([class_1, class_0])  # get upsampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjWflBGr2tEG",
        "outputId": "5e43ddfa-2b49-40ca-c86f-f8966c3f5790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1    23806\n",
            "0    23806\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# print the count of 0,1 in the label column after data up-sampling\n",
        "print(upsampled_data[\"label\"].value_counts()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vUo-cWXY2s45"
      },
      "outputs": [],
      "source": [
        "# convert upsampled_data from DataFram to an array \n",
        "data_upsampled = upsampled_data.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDA2aqmjSGZB"
      },
      "source": [
        "## Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "e_xBLlNQ2A1h"
      },
      "outputs": [],
      "source": [
        "# split the train data\n",
        "# training_set, validation_set = train_test_split(train, test_size=0.15)\n",
        "\n",
        "# split the up-sampled data\n",
        "training_set, validation_set = train_test_split(data_upsampled, test_size=0.15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE3epz7Rbi9y"
      },
      "source": [
        "# Visualizing/Inspecting a Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JkMQBCv7bZqm"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet networkx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "colors = cm.rainbow(np.linspace(0, 1, 50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z1zx-bxKbmhw"
      },
      "outputs": [],
      "source": [
        "def visualize(sample):\n",
        "    G=nx.Graph()\n",
        "    nodes = sample[0]\n",
        "    edges = sample[1]\n",
        "    \n",
        "    labeldict={}\n",
        "    node_color=[]\n",
        "    for i,n in enumerate(nodes):\n",
        "        G.add_node(i)\n",
        "        labeldict[i]=n\n",
        "        node_color.append(colors[hash(n)%len(colors)])\n",
        "\n",
        "    # a list of nodes:\n",
        "    for e in edges:\n",
        "        G.add_edge(e[0], e[1])\n",
        "        \n",
        "    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
        "    plt.show()\n",
        "    \n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "LXcjNBj0bpS4",
        "outputId": "dbf3fc84-bd52-43b6-d0a0-d531e3a39ba2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7f78d4d29d90>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plt.clf()\n",
        "visualize(training_set[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qnuEZ4GcDxd"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Boc6lvh9btcV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_vocab = 500\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "all_nodes = [s[0] for s in training_set]\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3nM8Dma1cLBL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "def prepare_single_batch(samples):\n",
        "    sample_nodes = [s[0] for s in samples]\n",
        "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n",
        "    sample_nodes = pad_sequences(sample_nodes, padding='post')\n",
        "    max_nodes_len = np.shape(sample_nodes)[1]\n",
        "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n",
        "    edges = [e for e in edges if len(e) > 0]\n",
        "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n",
        "    \n",
        "    all_nodes = np.reshape(sample_nodes, -1)\n",
        "    all_edges = np.concatenate(edges)\n",
        "\n",
        "    node_to_graph = np.reshape(node_to_graph, -1)\n",
        "    return {\n",
        "        'data': all_nodes,\n",
        "        'edges': all_edges,\n",
        "        'node2grah': node_to_graph,\n",
        "    }, np.array([s[2] for s in samples])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "p0ilot1ipV3B"
      },
      "outputs": [],
      "source": [
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
        "    while True:\n",
        "        dataset = list(dataset)\n",
        "        if shuffle:\n",
        "            random.shuffle(dataset)\n",
        "        l = len(dataset)\n",
        "        for ndx in range(0, l, batch_size):\n",
        "            batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n",
        "            yield prepare_single_batch(batch_samples)\n",
        "        if not repeat:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYVK4dj3cQsg",
        "outputId": "f7d9cdc8-c210-4884-a772-629ead95dca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\n",
            "[2 2 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 2 2 3 3 3 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 2 2 2 2 2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "edges\n",
            "[[  0   7]\n",
            " [  1   9]\n",
            " [  2   5]\n",
            " [  2  11]\n",
            " [  3   8]\n",
            " [  3   9]\n",
            " [  4   5]\n",
            " [  4   6]\n",
            " [  4   9]\n",
            " [  5   7]\n",
            " [  6   8]\n",
            " [  6  12]\n",
            " [  7  10]\n",
            " [  8  14]\n",
            " [ 10  11]\n",
            " [ 10  15]\n",
            " [ 11  16]\n",
            " [ 12  13]\n",
            " [ 13  17]\n",
            " [ 13  18]\n",
            " [ 14  17]\n",
            " [ 15  19]\n",
            " [ 16  20]\n",
            " [ 18  21]\n",
            " [ 18  22]\n",
            " [ 19  20]\n",
            " [ 40  42]\n",
            " [ 41  46]\n",
            " [ 42  45]\n",
            " [ 42  46]\n",
            " [ 43  44]\n",
            " [ 43  45]\n",
            " [ 44  46]\n",
            " [ 45  47]\n",
            " [ 47  48]\n",
            " [ 48  49]\n",
            " [ 48  50]\n",
            " [ 49  51]\n",
            " [ 50  52]\n",
            " [ 51  53]\n",
            " [ 52  53]\n",
            " [ 80  96]\n",
            " [ 80  97]\n",
            " [ 81  96]\n",
            " [ 82 101]\n",
            " [ 82 109]\n",
            " [ 83 102]\n",
            " [ 83 109]\n",
            " [ 84 106]\n",
            " [ 84 116]\n",
            " [ 85 107]\n",
            " [ 85 117]\n",
            " [ 86 108]\n",
            " [ 87 115]\n",
            " [ 87 118]\n",
            " [ 88 115]\n",
            " [ 93  89]\n",
            " [ 89 105]\n",
            " [ 90  91]\n",
            " [ 90  92]\n",
            " [ 90  96]\n",
            " [ 91  93]\n",
            " [ 91  97]\n",
            " [ 92  94]\n",
            " [ 98  92]\n",
            " [ 93  95]\n",
            " [ 94  95]\n",
            " [ 94  99]\n",
            " [ 95 100]\n",
            " [ 98 103]\n",
            " [ 98 104]\n",
            " [ 99 101]\n",
            " [100 102]\n",
            " [101 102]\n",
            " [103 106]\n",
            " [104 107]\n",
            " [105 110]\n",
            " [105 111]\n",
            " [106 108]\n",
            " [107 108]\n",
            " [110 112]\n",
            " [111 113]\n",
            " [112 114]\n",
            " [112 115]\n",
            " [113 114]\n",
            " [120 134]\n",
            " [120 153]\n",
            " [121 136]\n",
            " [121 154]\n",
            " [122 137]\n",
            " [122 155]\n",
            " [123 143]\n",
            " [124 146]\n",
            " [124 156]\n",
            " [125 145]\n",
            " [126 148]\n",
            " [126 157]\n",
            " [127 149]\n",
            " [127 158]\n",
            " [128 150]\n",
            " [128 159]\n",
            " [129 135]\n",
            " [129 143]\n",
            " [130 131]\n",
            " [130 133]\n",
            " [130 134]\n",
            " [131 132]\n",
            " [131 141]\n",
            " [132 135]\n",
            " [132 142]\n",
            " [133 138]\n",
            " [133 139]\n",
            " [134 136]\n",
            " [135 140]\n",
            " [136 137]\n",
            " [137 138]\n",
            " [139 140]\n",
            " [141 147]\n",
            " [142 145]\n",
            " [143 144]\n",
            " [144 151]\n",
            " [144 152]\n",
            " [145 146]\n",
            " [146 147]\n",
            " [148 149]\n",
            " [148 150]\n",
            " [149 151]\n",
            " [150 152]]\n",
            "node2grah\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "label [0 0 1 1]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(training_set, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)\n",
        "        print(v)\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9uCc9tKkLdn"
      },
      "source": [
        "# Saving Prediction Result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WmgD4S2WkTiQ"
      },
      "outputs": [],
      "source": [
        "# define function to save the csv file of the result after each trial\n",
        "def saveResult(y_pred, fileName):\n",
        "  submission = pd.DataFrame({'label': y_pred})\n",
        "  submission.index.name = 'id'\n",
        "  \n",
        "  submission.to_csv(fileName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l24YEFKBA00d"
      },
      "source": [
        "# Building Learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEVh6PirYiA-"
      },
      "source": [
        "## Frist trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-oDQ8b77e-Q"
      },
      "source": [
        "thoughts and observations for trial 0, plan for trial 1: \n",
        "\n",
        "<br/>\n",
        "\n",
        "I used **Graph Neural Network** as this task is a bioassay task for anticancer activity prediction, where each chemical compound is represented as a graph.\n",
        "\n",
        "I used this **Graph Neural Network** with the data that consider very unbalanced **without apply the Up-Sampling** on it\n",
        "\n",
        "After declaring the GNNInput, I defined the hyperparameters for GNN layer by loading first the **defualt hyperparameters of GNN** and set **`hidden_dim` to be 32** which represent the size of the output of all message passing layers\n",
        "\n",
        "then adding Graph Neural Network layer with the defined hyperparameters and calculating segmented mean based on segment_ids\n",
        "\n",
        "Finally, define the output layer of the model then building and compiling the model using **BinaryCrossentropy** for loss and the **AUC metric** to measure the performance of the network.\n",
        "\n",
        "<br/>\n",
        "\n",
        "While fitting the model I specified the value of batch size to be 16 and the value of epochs to be 10 and used the `validation_set` to validate our model\n",
        "\n",
        "<br/>\n",
        "\n",
        "From the result, we can say that unbalanced data affect the model accuracy and produce a low results \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruVRsMvcZjDD"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QkkRmqYR1Zm",
        "outputId": "a5ff4bcc-2d4d-4e9c-ae37-bdc5ac9cfa48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 32)           22464       ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,497\n",
            "Trainable params: 32,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,)) #Input layer for nodes (tokenized text data) \n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "\n",
        "# Graph Neural Network layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "# printing summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7rvu6CJg5yqY"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB-r6sfjBYh9"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyVFF4LTR1Zm",
        "outputId": "94c949ba-5019-424c-f11c-0a7e7de10874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 23s 15ms/step - loss: 0.2236 - auc: 0.5050 - val_loss: 0.1928 - val_auc: 0.6526\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 27s 20ms/step - loss: 0.1939 - auc: 0.6393 - val_loss: 0.1865 - val_auc: 0.6753\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 24s 18ms/step - loss: 0.1900 - auc: 0.6620 - val_loss: 0.1877 - val_auc: 0.6994\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1889 - auc: 0.6780 - val_loss: 0.1829 - val_auc: 0.7132\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1877 - auc: 0.6771 - val_loss: 0.1852 - val_auc: 0.7173\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 22s 17ms/step - loss: 0.1861 - auc: 0.6764 - val_loss: 0.2086 - val_auc: 0.7033\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 34s 26ms/step - loss: 0.1860 - auc: 0.6832 - val_loss: 0.1837 - val_auc: 0.7184\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1850 - auc: 0.6786 - val_loss: 0.1767 - val_auc: 0.7169\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1846 - auc: 0.6795 - val_loss: 0.1924 - val_auc: 0.6959\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 20s 15ms/step - loss: 0.1839 - auc: 0.6868 - val_loss: 0.1830 - val_auc: 0.7217\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dd0e668d0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XoapvMgZ64I"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TI_QxyDaDyx"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Yop1fc3cX1d"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOrQOhNq5704"
      },
      "source": [
        "## Second trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUEpMxxf7ijJ"
      },
      "source": [
        "thoughts and observations for trial 1, plan for trial 2:\n",
        "\n",
        "<br/>\n",
        "\n",
        "In this trial I used **the previous model with same configuration after applying the Up-Sampling technique** to the training dataset which was very unbalanced (by up-sample the positive class samples), in order to compare the results before and after Up-Sampling the data\n",
        "\n",
        "From the result, we can say that this model is fitting the data well and produce better result than applying the model on train data as it's (before Up-sampling)\n",
        "\n",
        "Based on these results, all the following trials will use the Up-Sampled data as it produce better results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVaOK0Zo571G"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnhExLzj571G",
        "outputId": "39b20cc6-fc28-4937-a643-fbcb16229148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 44s 17ms/step - loss: 0.6084 - auc: 0.7291 - val_loss: 0.5745 - val_auc: 0.7762\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 44s 17ms/step - loss: 0.5726 - auc: 0.7719 - val_loss: 0.5661 - val_auc: 0.7946\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5590 - auc: 0.7870 - val_loss: 0.5501 - val_auc: 0.8054\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5513 - auc: 0.7959 - val_loss: 0.5503 - val_auc: 0.8008\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5432 - auc: 0.8036 - val_loss: 0.5384 - val_auc: 0.8136\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5376 - auc: 0.8085 - val_loss: 0.5342 - val_auc: 0.8169\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5331 - auc: 0.8129 - val_loss: 0.5175 - val_auc: 0.8270\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5285 - auc: 0.8168 - val_loss: 0.5162 - val_auc: 0.8290\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5250 - auc: 0.8202 - val_loss: 0.5533 - val_auc: 0.8180\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5214 - auc: 0.8227 - val_loss: 0.5180 - val_auc: 0.8267\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dd12dfb50>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzOfMvms571G"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pKLELwUY571H"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pTgnpHAH571H"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo6s0H6T_8I9"
      },
      "source": [
        "## Third trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ERPTuY2H_6r"
      },
      "source": [
        "thoughts and observations for trial 2, plan for trial 3: \n",
        "\n",
        "<br/>\n",
        "\n",
        "I used **Graph Neural Network** as this task is a bioassay task for anticancer activity prediction, where each chemical compound is represented as a graph.\n",
        "\n",
        "I used this Graph Neural Network **with the Up-Sampled data**, in addition to applying one of the **GCN aggregation mechanisms** by tuning the message_passing mechanisms and **configure the message passing style to be GGNN**\n",
        "\n",
        "After declaring the GNNInput, I defined the hyperparameters for GNN layer by loading the **defualt hyperparameters of GNN** and set **`hidden_dim` to be 32** which represent the size of the output of all message passing layers, and **set `message_calculation_class` parameter to be GGNN**\n",
        "\n",
        "then adding Graph Neural Network layer with the defined hyperparameters and calculating segmented mean based on segment_ids\n",
        "\n",
        "Finally, define the output layer of the model then building and compiling the model using **BinaryCrossentropy** for loss and the **AUC metric** to measure the performance of the network.\n",
        "\n",
        "<br/>\n",
        "\n",
        "While fitting the model I specified the value of batch size to be 16 and the value of epochs to be 10 and used the `validation_set` to validate our model\n",
        "\n",
        "<br/>\n",
        "\n",
        "From the result, we can say that the results is much better than using the model without applying GCN aggregation mechanisms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFypzY9D_8JK"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYyAhJVG_8JK",
        "outputId": "a2e28647-1f19-444e-8c5e-7bb4dd514a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 20)           10000       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                    (None, 32)           47808       ['embedding_1[0][0]',            \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n",
            " mbda)                                                            'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            33          ['tf.math.segment_mean_1[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 57,841\n",
            "Trainable params: 57,841\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be GGNN (Gated Graph Neural Networks)\n",
        "params['message_calculation_class'] = 'GGNN'\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "igjBXr6D_8JL"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7MdVauh_8JL"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3pBoRCr_8JM",
        "outputId": "78e832f9-540d-44a5-a69b-a77f231d5043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 90s 34ms/step - loss: 0.6197 - auc: 0.7093 - val_loss: 0.5731 - val_auc: 0.7677\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 75s 30ms/step - loss: 0.5696 - auc: 0.7694 - val_loss: 0.5404 - val_auc: 0.8078\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 70s 28ms/step - loss: 0.5292 - auc: 0.8128 - val_loss: 0.4993 - val_auc: 0.8441\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 69s 27ms/step - loss: 0.4912 - auc: 0.8431 - val_loss: 0.4789 - val_auc: 0.8535\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 70s 28ms/step - loss: 0.4662 - auc: 0.8604 - val_loss: 0.4501 - val_auc: 0.8748\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 70s 28ms/step - loss: 0.4416 - auc: 0.8768 - val_loss: 0.4204 - val_auc: 0.8906\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 68s 27ms/step - loss: 0.4219 - auc: 0.8882 - val_loss: 0.4417 - val_auc: 0.8868\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 73s 29ms/step - loss: 0.4066 - auc: 0.8963 - val_loss: 0.3926 - val_auc: 0.9050\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 74s 29ms/step - loss: 0.3914 - auc: 0.9045 - val_loss: 0.3693 - val_auc: 0.9158\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 69s 27ms/step - loss: 0.3751 - auc: 0.9124 - val_loss: 0.3658 - val_auc: 0.9279\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dcbeb9c50>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY2D51XQ_8JM"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "S2MDGKkt_8JM"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "i2xLxyyl_8JM"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial3.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ss9VFgs_88k"
      },
      "source": [
        "## Fourth trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khaqn9n1Si7Z"
      },
      "source": [
        "thoughts and observations for trial 3, plan for trial 4: \n",
        "\n",
        "<br/>\n",
        "\n",
        "I used **Graph Neural Network** as this task is a bioassay task for anticancer activity prediction, where each chemical compound is represented as a graph.\n",
        "\n",
        "I used this Graph Neural Network **with the Up-Sampled data**, in addition to applying one of the **GCN aggregation mechanisms** by tuning the message_passing mechanisms and **configure the message passing style to be RGCN**\n",
        "\n",
        "After declaring the GNNInput, I defined the hyperparameters for GNN layer by loading the **defualt hyperparameters of GNN** and set **`hidden_dim` to be 32** which represent the size of the output of all message passing layers, and **set `message_calculation_class` parameter to be RGCN**\n",
        "\n",
        "then adding Graph Neural Network layer with the defined hyperparameters and calculating segmented mean based on segment_ids\n",
        "\n",
        "Finally, define the output layer of the model then building and compiling the model using **BinaryCrossentropy** for loss and the **AUC metric** to measure the performance of the network.\n",
        "\n",
        "<br/>\n",
        "\n",
        "While fitting the model I specified the value of batch size to be 16 and the value of epochs to be 10 and used the `validation_set` to validate our model\n",
        "\n",
        "<br/>\n",
        "\n",
        "From the result, we can say that the results is much better than using the model without applying GCN aggregation mechanisms, but in this trail the result is lower than previous model whose message_calculation_class parameter equals to GGNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srqqUWsO_88l"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m-7KlIs_88l",
        "outputId": "3ef61a13-eec3-4a95-a110-9499efc102cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 20)           10000       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                    (None, 32)           22464       ['embedding_2[0][0]',            \n",
            "                                                                  'input_8[0][0]',                \n",
            "                                                                  'input_9[0][0]',                \n",
            "                                                                  'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TFOpLa  (None, 32)          0           ['gnn_2[0][0]',                  \n",
            " mbda)                                                            'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            33          ['tf.math.segment_mean_2[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,497\n",
            "Trainable params: 32,497\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGCN (Relational Graph Convolutional Networks)\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the output layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "g4_ydeAj_88m"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU2JZSlI_88m"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPd9UL2m_88n",
        "outputId": "6201655c-9b1a-4abd-d963-8052d1e78ebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 51s 19ms/step - loss: 0.6265 - auc: 0.7048 - val_loss: 0.5988 - val_auc: 0.7436\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5986 - auc: 0.7454 - val_loss: 0.5906 - val_auc: 0.7552\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5888 - auc: 0.7579 - val_loss: 0.5723 - val_auc: 0.7810\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5748 - auc: 0.7744 - val_loss: 0.5534 - val_auc: 0.7990\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5634 - auc: 0.7855 - val_loss: 0.5528 - val_auc: 0.7988\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 42s 17ms/step - loss: 0.5521 - auc: 0.7973 - val_loss: 0.5274 - val_auc: 0.8187\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5388 - auc: 0.8086 - val_loss: 0.5345 - val_auc: 0.8172\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5296 - auc: 0.8153 - val_loss: 0.5064 - val_auc: 0.8338\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5208 - auc: 0.8227 - val_loss: 0.5085 - val_auc: 0.8327\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5213 - auc: 0.8221 - val_loss: 0.5053 - val_auc: 0.8375\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dcae75a10>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM9bykVw_88n"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BCpLPbBd_88o"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ggk1APkQ_88o"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jlpvXCoVXQh"
      },
      "source": [
        "## Fifth trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHDe1ZFeWPob"
      },
      "source": [
        "thoughts and observations for trial 4, plan for trial 5: \n",
        "\n",
        "<br/>\n",
        "\n",
        "I used **Graph Neural Network** as this task is a bioassay task for anticancer activity prediction, where each chemical compound is represented as a graph.\n",
        "\n",
        "I used this Graph Neural Network **with the Up-Sampled data**, in addition to applying one of the **GCN aggregation mechanisms** by tuning the message_passing mechanisms and **configure the message passing style to be RGAT**\n",
        "\n",
        "After declaring the GNNInput, I defined the hyperparameters for GNN layer by loading the **defualt hyperparameters of GNN** and set **`hidden_dim` to be 32** which represent the size of the output of all message passing layers, and **set `message_calculation_class` parameter to be RGAT**, and set the number of parallel (independent) weighted sums that are computed **`num_heads` to be 4**\n",
        "\n",
        "then adding Graph Neural Network layer with the defined hyperparameters and calculating segmented mean based on segment_ids\n",
        "\n",
        "Finally, define the output layer of the model then building and compiling the model using **BinaryCrossentropy** for loss and the **AUC metric** to measure the performance of the network.\n",
        "\n",
        "<br/>\n",
        "\n",
        "While fitting the model I specified the value of batch size to be 16 and the value of epochs to be 10 and used the `validation_set` to validate our model\n",
        "\n",
        "<br/>\n",
        "\n",
        "From the result, we can say that the results is much better than the previous trial which has message_calculation_class parameter equals to RGCN, but it is lower than the model whose message_calculation_class parameter equals to GGNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZCCzThWVXQt"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9Q-Cd-NVXQt",
        "outputId": "1023f9c7-2a6a-4d96-cc55-900a5bbec148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_12[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 20)           10000       ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                    (None, 32)           22720       ['embedding_3[0][0]',            \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 32)          0           ['gnn_3[0][0]',                  \n",
            " mbda)                                                            'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            33          ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 32,753\n",
            "Trainable params: 32,753\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGAT (Relational Graph Attention Networks)\n",
        "params['message_calculation_class'] = 'RGAT'\n",
        "# configures the number of parallel (independent) weighted sums that are computed, whose results are concatenated to obtain the final result.\n",
        "params[\"num_heads\"] = 4\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "baj-c-KoVXQu"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLmHWzu2VXQu"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HZCWq9uVXQu",
        "outputId": "065e50d9-f908-4260-8d10-f138caad97a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 65s 24ms/step - loss: 0.6232 - auc: 0.7103 - val_loss: 0.6078 - val_auc: 0.7435\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 59s 23ms/step - loss: 0.5844 - auc: 0.7595 - val_loss: 0.5664 - val_auc: 0.7830\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 59s 23ms/step - loss: 0.5624 - auc: 0.7836 - val_loss: 0.5463 - val_auc: 0.8004\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 59s 23ms/step - loss: 0.5464 - auc: 0.7999 - val_loss: 0.5282 - val_auc: 0.8180\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 59s 23ms/step - loss: 0.5347 - auc: 0.8092 - val_loss: 0.5205 - val_auc: 0.8308\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 60s 24ms/step - loss: 0.5198 - auc: 0.8227 - val_loss: 0.5172 - val_auc: 0.8342\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 60s 24ms/step - loss: 0.5082 - auc: 0.8322 - val_loss: 0.4872 - val_auc: 0.8499\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 60s 24ms/step - loss: 0.4969 - auc: 0.8404 - val_loss: 0.4969 - val_auc: 0.8525\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 60s 24ms/step - loss: 0.4892 - auc: 0.8460 - val_loss: 0.4684 - val_auc: 0.8609\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 60s 24ms/step - loss: 0.4852 - auc: 0.8494 - val_loss: 0.4635 - val_auc: 0.8691\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dd1208610>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL4xn0HGVXQu"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "txkvy4urVXQv"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Z4d_eVY-VXQv"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial5.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIfZY-a7g90Q"
      },
      "source": [
        "## Sixth trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j85osVUxX1gj"
      },
      "source": [
        "thoughts and observations for trial 5, plan for trial 6: \n",
        "\n",
        "<br/>\n",
        "\n",
        "I used **Graph Neural Network** as this task is a bioassay task for anticancer activity prediction, where each chemical compound is represented as a graph.\n",
        "\n",
        "I used this Graph Neural Network **with the Up-Sampled data**, in addition to applying one of the **GCN aggregation mechanisms** by tuning the message_passing mechanisms and **configure the message passing style to be RGIN**\n",
        "\n",
        "After declaring the GNNInput, I defined the hyperparameters for GNN layer by loading the **defualt hyperparameters of GNN** and set **`hidden_dim` to be 32** which represent the size of the output of all message passing layers, and **set `message_calculation_class` parameter to be RGIN**, and set the **`num_aggr_MLP_hidden_layers` to be 2** as it is required parameter for RGIN\n",
        "\n",
        "then adding Graph Neural Network layer with the defined hyperparameters and calculating segmented mean based on segment_ids\n",
        "\n",
        "Finally, define the output layer of the model then building and compiling the model using **BinaryCrossentropy** for loss and the **AUC metric** to measure the performance of the network.\n",
        "\n",
        "<br/>\n",
        "\n",
        "While fitting the model I specified the value of batch size to be 16 and the value of epochs to be 10 and used the `validation_set` to validate our model\n",
        "\n",
        "<br/>\n",
        "\n",
        "From the result, we can say that the results is much better than the previous trial which has message_calculation_class parameter equals to RGCN, but it is lower than the model whose message_calculation_class parameter equals to GGNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQt89uBIg90Q"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6turn-pg90R",
        "outputId": "c99b434d-7468-4252-a4ae-7e4f270609a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_4 (TFOpLamb  ()                  0           ['input_15[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 20)           10000       ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  ()                  0           ['tf.math.reduce_max_4[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_4 (GNN)                    (None, 32)           34752       ['embedding_4[0][0]',            \n",
            "                                                                  'input_14[0][0]',               \n",
            "                                                                  'input_15[0][0]',               \n",
            "                                                                  'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_4 (TFOpLa  (None, 32)          0           ['gnn_4[0][0]',                  \n",
            " mbda)                                                            'input_15[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            33          ['tf.math.segment_mean_4[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 44,785\n",
            "Trainable params: 44,785\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the message passing style to be RGIN (Relational Graph Isomorphism Networks)\n",
        "params['message_calculation_class'] = 'RGIN'\n",
        "params['num_aggr_MLP_hidden_layers'] = 2\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6fgFjeMeg90S"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Eaz4iOg90S"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG9TqWJeg90S",
        "outputId": "fe979263-0d54-48f2-bf35-f8ac7b5fd7f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 56s 21ms/step - loss: 0.6270 - auc: 0.7064 - val_loss: 0.6064 - val_auc: 0.7336\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 53s 21ms/step - loss: 0.6035 - auc: 0.7394 - val_loss: 0.5844 - val_auc: 0.7624\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 57s 23ms/step - loss: 0.5869 - auc: 0.7606 - val_loss: 0.5846 - val_auc: 0.7821\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 53s 21ms/step - loss: 0.5655 - auc: 0.7830 - val_loss: 0.5585 - val_auc: 0.7899\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 53s 21ms/step - loss: 0.5545 - auc: 0.7929 - val_loss: 0.5488 - val_auc: 0.8125\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 53s 21ms/step - loss: 0.5421 - auc: 0.8052 - val_loss: 0.5480 - val_auc: 0.8022\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 54s 21ms/step - loss: 0.5335 - auc: 0.8131 - val_loss: 0.5089 - val_auc: 0.8320\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 53s 21ms/step - loss: 0.5289 - auc: 0.8170 - val_loss: 0.5473 - val_auc: 0.8031\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 53s 21ms/step - loss: 0.5223 - auc: 0.8222 - val_loss: 0.5083 - val_auc: 0.8390\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 56s 22ms/step - loss: 0.5199 - auc: 0.8244 - val_loss: 0.4895 - val_auc: 0.8484\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dc5621a10>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQLz0BdRg90T"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "F9WiqEy3g90T"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "j7zMCFD7g90T"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial6.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN4lsnn7siqD"
      },
      "source": [
        "## Seventh trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V75CBIOUYyTs"
      },
      "source": [
        "thoughts and observations for trial 6, plan for trial 7: \n",
        "\n",
        "<br/>\n",
        "\n",
        "I used **Graph Neural Network** as this task is a bioassay task for anticancer activity prediction, where each chemical compound is represented as a graph.\n",
        "\n",
        "I used this Graph Neural Network **with the Up-Sampled data**, in addition to applying one of the **GCN aggregation mechanisms** by tuning the message_passing mechanisms and **configure the message passing style to be GNN_Edge_MLP**\n",
        "\n",
        "After declaring the GNNInput, I defined the hyperparameters for GNN layer by loading the **defualt hyperparameters of GNN_Edge_MLP** and set **`hidden_dim` to be 32** which represent the size of the output of all message passing layers, and **configure all the parameters that needed by GNN_Edge_MLP**\n",
        "\n",
        "then adding Graph Neural Network layer with the defined hyperparameters and calculating segmented mean based on segment_ids\n",
        "\n",
        "Finally, define the output layer of the model then building and compiling the model using **BinaryCrossentropy** for loss and the **AUC metric** to measure the performance of the network.\n",
        "\n",
        "<br/>\n",
        "\n",
        "While fitting the model I specified the value of batch size to be 16 and the value of epochs to be 10 and used the `validation_set` to validate our model\n",
        "\n",
        "<br/>\n",
        "\n",
        "From the result, we can say that the result is lower than the model whose message_calculation_class parameter equals to GGNN, but it is better than other trials\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CblXIkqOsiqE"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyAdeQVasiqF",
        "outputId": "85e224a1-e2ba-44eb-86a7-e9b388a4cea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_18 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_16 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_5 (TFOpLamb  ()                  0           ['input_18[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, 20)           10000       ['input_16[0][0]']               \n",
            "                                                                                                  \n",
            " input_17 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  ()                  0           ['tf.math.reduce_max_5[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_5 (GNN)                    (None, 32)           15232       ['embedding_5[0][0]',            \n",
            "                                                                  'input_17[0][0]',               \n",
            "                                                                  'input_18[0][0]',               \n",
            "                                                                  'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_5 (TFOpLa  (None, 32)          0           ['gnn_5[0][0]',                  \n",
            " mbda)                                                            'input_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            33          ['tf.math.segment_mean_5[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,265\n",
            "Trainable params: 25,265\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters of GNN_Edge_MLP\n",
        "params = GNN_Edge_MLP.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the parameters that needed by GNN_Edge_MLP\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'gru'   # has to be one of 'mean', 'mlp', 'gru'!\n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.2\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "R6O7XTWasiqG"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDpwkP6JsiqG"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8kGjNTssiqG",
        "outputId": "ee820e46-4043-488a-c8dc-5e8e4c2028d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 53s 20ms/step - loss: 0.6126 - auc: 0.7230 - val_loss: 0.5722 - val_auc: 0.7751\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 50s 20ms/step - loss: 0.5707 - auc: 0.7758 - val_loss: 0.5486 - val_auc: 0.8116\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 50s 20ms/step - loss: 0.5499 - auc: 0.8014 - val_loss: 0.5253 - val_auc: 0.8219\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 49s 19ms/step - loss: 0.5336 - auc: 0.8152 - val_loss: 0.5292 - val_auc: 0.8312\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 48s 19ms/step - loss: 0.5202 - auc: 0.8277 - val_loss: 0.5072 - val_auc: 0.8438\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 48s 19ms/step - loss: 0.5112 - auc: 0.8351 - val_loss: 0.4875 - val_auc: 0.8541\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 48s 19ms/step - loss: 0.4998 - auc: 0.8437 - val_loss: 0.4818 - val_auc: 0.8544\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 48s 19ms/step - loss: 0.4934 - auc: 0.8479 - val_loss: 0.4715 - val_auc: 0.8653\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 48s 19ms/step - loss: 0.4842 - auc: 0.8543 - val_loss: 0.4605 - val_auc: 0.8683\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 47s 19ms/step - loss: 0.4800 - auc: 0.8575 - val_loss: 0.4592 - val_auc: 0.8733\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dc2f3e090>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eerm39iEsiqH"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "YVA8jej7siqH"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "iQQ8B0wusiqH"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial7.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd32KpnZ5SFx"
      },
      "source": [
        "## Eighth trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOCMNMK1aApv"
      },
      "source": [
        "thoughts and observations for trial 7, plan for trial 8: \n",
        "\n",
        "<br/>\n",
        "\n",
        "I used **Graph Neural Network** as this task is a bioassay task for anticancer activity prediction, where each chemical compound is represented as a graph.\n",
        "\n",
        "I used this Graph Neural Network **with the Up-Sampled data**, in addition to applying one of the **GCN aggregation mechanisms** by tuning the message_passing mechanisms and **configure the message passing style to be GNN_FiLM**\n",
        "\n",
        "After declaring the GNNInput, I defined the hyperparameters for GNN layer by loading the **defualt hyperparameters of GNN_FiLM** and set **`hidden_dim` to be 32** which represent the size of the output of all message passing layers, and **configure all the parameters that needed by GNN_FiLM**\n",
        "\n",
        "then adding Graph Neural Network layer with the defined hyperparameters and calculating segmented mean based on segment_ids\n",
        "\n",
        "Finally, define the output layer of the model then building and compiling the model using **BinaryCrossentropy** for loss and the **AUC metric** to measure the performance of the network.\n",
        "\n",
        "<br/>\n",
        "\n",
        "While fitting the model I specified the value of batch size to be 16 and the value of epochs to be 10 and used the `validation_set` to validate our model\n",
        "\n",
        "<br/>\n",
        "\n",
        "From the result, we can say that the result of this trial is mush lower than other models that applying the GCN aggregation mechanisms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrGR3b145SF6"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqKDvHSr5SF7",
        "outputId": "eea62379-e724-4fa7-80b1-241ae910b252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_19 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_6 (TFOpLamb  ()                  0           ['input_21[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, 20)           10000       ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  ()                  0           ['tf.math.reduce_max_6[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_6 (GNN)                    (None, 32)           7040        ['embedding_6[0][0]',            \n",
            "                                                                  'input_20[0][0]',               \n",
            "                                                                  'input_21[0][0]',               \n",
            "                                                                  'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_6 (TFOpLa  (None, 32)          0           ['gnn_6[0][0]',                  \n",
            " mbda)                                                            'input_21[0][0]']               \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            33          ['tf.math.segment_mean_6[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,073\n",
            "Trainable params: 17,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters of GNN_FiLM\n",
        "params = GNN_FiLM.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 32\n",
        "# configures the parameters that needed by GNN_FiLM\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'gru'   # has to be one of 'mean', 'mlp', 'gru'!\n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.2\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "KO7ALaZ45SF8"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI0jnU5t5SF9"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-14iyWP-5SF9",
        "outputId": "7ecc00bc-9593-4e39-f5d7-e6ffc9bd0f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 46s 17ms/step - loss: 0.6344 - auc: 0.6929 - val_loss: 0.6153 - val_auc: 0.7222\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.6107 - auc: 0.7294 - val_loss: 0.6097 - val_auc: 0.7593\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5949 - auc: 0.7497 - val_loss: 0.5935 - val_auc: 0.7674\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5799 - auc: 0.7658 - val_loss: 0.5705 - val_auc: 0.7865\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5710 - auc: 0.7779 - val_loss: 0.5553 - val_auc: 0.7973\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5629 - auc: 0.7859 - val_loss: 0.5450 - val_auc: 0.8082\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5558 - auc: 0.7939 - val_loss: 0.5375 - val_auc: 0.8101\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5528 - auc: 0.7968 - val_loss: 0.5345 - val_auc: 0.8165\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5488 - auc: 0.8008 - val_loss: 0.5329 - val_auc: 0.8181\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 43s 17ms/step - loss: 0.5480 - auc: 0.8036 - val_loss: 0.5348 - val_auc: 0.8193\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dc0bc5050>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53yoelOq5SF9"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "VsI3o22j5SF9"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "eQC1NdsS5SF9"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial8.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ISNbZaKDX80"
      },
      "source": [
        "## As the previous trails cover all possible GCN aggregation mechanisms (aka message_passing mechanisms) used in the graph convolution layer represented in Graph Neural Networks documentation: https://github.com/microsoft/tf2-gnn\n",
        "\n",
        "## And out of all trials the best two trails that give the highest accuracy are : Trial_3 & Trial_7\n",
        "\n",
        "## The following and last two trials will take these best models and adjust thier hyperparamters to achieve better accuracy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSkUU0KVZ6W5"
      },
      "source": [
        "## Ninth trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkhJqUX7bFrC"
      },
      "source": [
        "thoughts and observations for trial 8, plan for trial 9:\n",
        "\n",
        "<br/>\n",
        "\n",
        "In this trial I used **the same model that used in the Third trial** which is **Graph Neural Network with message_passing mechanisms equals to GGNN**\n",
        "after changing its hyperparameter by setting `hidden_dim` to be 16 instead of 32 and test the model and found that it decreased the accuracy, so I **changed the `hidden_dim` agian to be 64**and this help in improving the model result\n",
        "\n",
        "\n",
        "From the result, we can say that tuning hyperparameters produce better results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK0zK1IZZ6XC"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE1SwqkQZ6XD",
        "outputId": "fdf17a11-05c2-4daf-8159-a2479b2a7976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_27 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_25 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_8 (TFOpLamb  ()                  0           ['input_27[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)        (None, 20)           10000       ['input_25[0][0]']               \n",
            "                                                                                                  \n",
            " input_26 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TFOpLa  ()                  0           ['tf.math.reduce_max_8[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_8 (GNN)                    (None, 64)           171392      ['embedding_8[0][0]',            \n",
            "                                                                  'input_26[0][0]',               \n",
            "                                                                  'input_27[0][0]',               \n",
            "                                                                  'tf.__operators__.add_8[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_8 (TFOpLa  (None, 64)          0           ['gnn_8[0][0]',                  \n",
            " mbda)                                                            'input_27[0][0]']               \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            65          ['tf.math.segment_mean_8[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 181,457\n",
            "Trainable params: 181,457\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters\n",
        "params = GNN.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 64\n",
        "# configures the message passing style to be GGNN (Gated Graph Neural Networks)\n",
        "params['message_calculation_class'] = 'GGNN'\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Y26LN2kVZ6XD"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1riGdpgsZ6XD"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nTJthr3Z6XE",
        "outputId": "f78e3e1e-1c03-4c60-d5a8-56494709f58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 151s 58ms/step - loss: 0.6035 - auc: 0.7365 - val_loss: 0.5916 - val_auc: 0.7691\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 145s 57ms/step - loss: 0.5452 - auc: 0.7990 - val_loss: 0.5173 - val_auc: 0.8289\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 149s 59ms/step - loss: 0.5089 - auc: 0.8299 - val_loss: 0.5032 - val_auc: 0.8467\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 145s 57ms/step - loss: 0.4788 - auc: 0.8524 - val_loss: 0.4730 - val_auc: 0.8569\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 146s 58ms/step - loss: 0.4516 - auc: 0.8705 - val_loss: 0.4135 - val_auc: 0.8937\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 151s 60ms/step - loss: 0.4193 - auc: 0.8899 - val_loss: 0.4127 - val_auc: 0.8958\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 147s 58ms/step - loss: 0.3912 - auc: 0.9048 - val_loss: 0.3934 - val_auc: 0.9069\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 145s 57ms/step - loss: 0.3676 - auc: 0.9161 - val_loss: 0.3700 - val_auc: 0.9222\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 142s 56ms/step - loss: 0.3457 - auc: 0.9255 - val_loss: 0.3230 - val_auc: 0.9373\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 141s 56ms/step - loss: 0.3258 - auc: 0.9336 - val_loss: 0.3200 - val_auc: 0.9467\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dbba50690>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMyTWE8kZ6XE"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "IVeU_p88Z6XE"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "v4nI-bH4Z6XE"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial9.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl6uNvUgZ6XE"
      },
      "source": [
        "## Tenth trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zC53UkSdPIO"
      },
      "source": [
        "thoughts and observations for trial 9, plan for trial 10:\n",
        "\n",
        "<br/>\n",
        "\n",
        "In this trial I used **the same model that used in the Seventh trial** which is **Graph Neural Network with message_passing mechanisms equals to GNN_Edge_MLP**\n",
        "after changing its hyperparameter by setting `hidden_dim` to be 64 instead of 32 and set `global_exchange_mode` to be 'mlp'instead of 'gru', also set `layer_input_dropout_rate` to be 0.1 instead of 0.2and found that this help in improving the model result\n",
        "\n",
        "\n",
        "From the result, we can say that tuning hyperparameters produce better results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHzTTv0-Z6XE"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKz-GpDRZ6XE",
        "outputId": "981ac05d-4412-4ad6-bffa-f54d58ad47cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_30 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_28 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_9 (TFOpLamb  ()                  0           ['input_30[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_9 (Embedding)        (None, 20)           10000       ['input_28[0][0]']               \n",
            "                                                                                                  \n",
            " input_29 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_9 (TFOpLa  ()                  0           ['tf.math.reduce_max_9[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_9 (GNN)                    (None, 64)           59136       ['embedding_9[0][0]',            \n",
            "                                                                  'input_29[0][0]',               \n",
            "                                                                  'input_30[0][0]',               \n",
            "                                                                  'tf.__operators__.add_9[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_9 (TFOpLa  (None, 64)          0           ['gnn_9[0][0]',                  \n",
            " mbda)                                                            'input_30[0][0]']               \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            65          ['tf.math.segment_mean_9[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,201\n",
            "Trainable params: 69,201\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = keras.Input(batch_shape=(None,))\n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 20)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "# declare the GNNInput that take the features of node, the edge, the created list 'node2graph', and number of graphs (number of samples)\n",
        "gnn_input = GNNInput(\n",
        "    node_features = embeded,\n",
        "    adjacency_lists = (edge,),\n",
        "    node_to_graph_map = node2graph, \n",
        "    num_graphs = num_graph,\n",
        ")\n",
        "\n",
        "\n",
        "# configure the hyperparameters of GNN layers\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "# \n",
        "# frist load the defualt hyperparameters of GNN_Edge_MLP\n",
        "params = GNN_Edge_MLP.get_default_hyperparameters()\n",
        "# sets the size of the output of all message passing layers\n",
        "params[\"hidden_dim\"] = 64\n",
        "# configures the parameters that needed by GNN_Edge_MLP\n",
        "params['num_layers'] = 4\n",
        "params['dense_every_num_layers'] = 2\n",
        "params['residual_every_num_layers'] = 2\n",
        "params['use_inter_layer_layernorm'] = 2\n",
        "params['initial_node_representation_activation'] = 'tanh'\n",
        "params['dense_intermediate_layer_activation'] = 'tanh'\n",
        "params['message_calculation_class'] = 'RGCN'\n",
        "params['global_exchange_mode'] = 'mlp'   # has to be one of 'mean', 'mlp', 'gru'!\n",
        "params['global_exchange_every_num_layers'] = 1000\n",
        "params['global_exchange_weighting_fun'] = 'softmax'\n",
        "params['global_exchange_num_heads'] = 4\n",
        "params['global_exchange_dropout_rate'] = 0.2\n",
        "params['layer_input_dropout_rate'] = 0.1\n",
        "\n",
        "# Implements a deep Graph Neural Network\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "\n",
        "\n",
        "# Computes the mean along segments of a tensor\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data = gnn_out,\n",
        "    segment_ids = node2graph\n",
        ")\n",
        "\n",
        "# Define the out put layer of the model\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "model = Model(\n",
        "    inputs = {\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs = pred\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "MgZX2ir5Z6XF"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pLUEkKeZ6XF"
      },
      "source": [
        "### Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPOU2aj4Z6XF",
        "outputId": "b6874b8b-a09e-4982-ca7e-d2d58c52f4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2530/2530 [==============================] - 93s 36ms/step - loss: 0.5797 - auc: 0.7673 - val_loss: 0.5353 - val_auc: 0.8168\n",
            "Epoch 2/10\n",
            "2530/2530 [==============================] - 89s 35ms/step - loss: 0.5276 - auc: 0.8218 - val_loss: 0.4945 - val_auc: 0.8495\n",
            "Epoch 3/10\n",
            "2530/2530 [==============================] - 89s 35ms/step - loss: 0.4993 - auc: 0.8458 - val_loss: 0.4754 - val_auc: 0.8664\n",
            "Epoch 4/10\n",
            "2530/2530 [==============================] - 89s 35ms/step - loss: 0.4757 - auc: 0.8625 - val_loss: 0.4547 - val_auc: 0.8733\n",
            "Epoch 5/10\n",
            "2530/2530 [==============================] - 89s 35ms/step - loss: 0.4543 - auc: 0.8756 - val_loss: 0.4413 - val_auc: 0.8868\n",
            "Epoch 6/10\n",
            "2530/2530 [==============================] - 90s 35ms/step - loss: 0.4378 - auc: 0.8855 - val_loss: 0.4189 - val_auc: 0.8979\n",
            "Epoch 7/10\n",
            "2530/2530 [==============================] - 89s 35ms/step - loss: 0.4262 - auc: 0.8916 - val_loss: 0.4095 - val_auc: 0.9031\n",
            "Epoch 8/10\n",
            "2530/2530 [==============================] - 90s 35ms/step - loss: 0.4153 - auc: 0.8983 - val_loss: 0.3926 - val_auc: 0.9098\n",
            "Epoch 9/10\n",
            "2530/2530 [==============================] - 89s 35ms/step - loss: 0.4016 - auc: 0.9056 - val_loss: 0.3911 - val_auc: 0.9143\n",
            "Epoch 10/10\n",
            "2530/2530 [==============================] - 89s 35ms/step - loss: 0.3967 - auc: 0.9084 - val_loss: 0.4346 - val_auc: 0.9055\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dbbc20690>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# calculate steps_per_epoch for training and validation data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "# training the model for 5 epochs\n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch = num_batchs,\n",
        "    epochs = 10,\n",
        "    validation_data = gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps = num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-nZx_B-Z6XF"
      },
      "source": [
        "### Predition & Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "rok8Ha5jZ6XF"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(\n",
        "    gen_batch(test, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "sax0K1eCZ6XF"
      },
      "outputs": [],
      "source": [
        "saveResult(y_pred, 'sample_submission_trial10.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os5YUiTX2UT5"
      },
      "source": [
        "# Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_AJ5LIz2Vz4"
      },
      "source": [
        "## ðŸŒˆ Based on the provided template, describe the format of the input file (sdf file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SKwq3M22WBI"
      },
      "source": [
        "One of the most widely used industry standards are chemical table file formats, like the Structure Data Format (SDF) files. They are text files that adhere to a strict format for representing multiple chemical structure records and associated data fields. --Wikipedia\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br/>\n",
        "\n",
        "The input file is structure data file (SDF). It contains information about the chemical composition of a molecule. SDF file store information about position of individual atom in the chemical compound and also tells about the connections. Different molecules are delimited by &dollar;&dollar;&dollar;&dollar; expression.\n",
        "\n",
        "Each sample starts with header which tells about the name/title of the compound. Other sections includes information about Atom count, version number, connections etc. Atom block tells about the elements of the compound. Bond/Edge block tells about the bonding structure of the compound. These both blocks are used to get information about the compound and saving them in form of edges and nodes. Each node is the atom given in the chemical molecule.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSVJ0pbN2WNa"
      },
      "source": [
        "## ðŸŒˆ What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QALa0PDz2qHU"
      },
      "source": [
        "The input tensors in this network are:\n",
        "\n",
        "- **data:** The data contains the nodes of the chemical compound in the tokenized form. Nodes for each compound are extracted, then they are tokenized using the tokenizer and finally padding is done using pad_sequence method. The shape for each batch is **[batch_size*max_len_nodes]**, where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done.\n",
        "\n",
        "- **edge:** edge is the input tensor which carries information about connections between atoms. The shape of edge is **[sum_of_all_edges,2]**. The sum_of_all_edges represents the sum(no. of edges of each sample) of the batch_size. For example in a batch of 3 samples, the number of edges in sample 1: 21, sample 2: 20 and sample 3: 40. So the size of edge tensor would be [81,2].\n",
        "\n",
        "- **node2graph:** It is the input tensor which is used for segmented mean and contains information about segmented ids. The shape for each batch is **[batch_size*max_len_nodes]**, where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYEqPag02qKZ"
      },
      "source": [
        "## ðŸŒˆ For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQZEq3Xc20z4"
      },
      "source": [
        "**gnn_out:** \n",
        "\n",
        "The gnn_out is of shape [batch_size_node_dimension,hidden layers], where batch_size_node_dimension is the dimension of the input data (node) vector (dimension of tokenized vector for the complete batch). It represents the aggregation output of the model for each hidden layer.\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "<br/>\n",
        "\n",
        "**avg:**\n",
        "\n",
        "Average takes the segmented mean of the gnn_out based on the segmented ids. For each sample in the batch_size, the output of gnn_out is [tokenized_vector_dimension, hidden_layers]. Each sample has one segment id. Thus the segment_mean takes the mean of all the output data in the gnn_out output and represents one sample with one number for each hidden layer. The final output of the avg tensor is of shape [batch_size, hidden_layer]. It is a way of collecting information for each sample and representing it in the form of mean data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e98ZUbZm22OE"
      },
      "source": [
        "## ðŸŒˆ What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fanM0fTb22Wk"
      },
      "source": [
        "**segment_mean:** takes the mean of the data which have same segmented ids.\n",
        "\n",
        "**reduce_mean:** computes the mean of elements across dimensions of a tensor given the arguments.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br/>\n",
        "\n",
        "**pred:** The final output (pred) tells about the probability of a chemical compound to be active for the cancer cell or not. The shape of pred is [batch_size,1]. Thus for each sample, the final output is a number which represents the probability associated with each chemical compound about its activity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp2Z5oe7N1M3"
      },
      "source": [
        "## ðŸŒˆ What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld9EKk6xN1NE"
      },
      "source": [
        "The template implements the default setting of the number of layers in the GCN network which is 4 as given in the documentaion. The default message passing method is RGCN (Relational Graph Convolutional Networks). Using multiple GCN helps in incorporating all the graph complexity properly and thus creates a better model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SCZaTk6POkXF",
        "EG7iwHNbO_HM",
        "Lh4P8Pf2RtC7",
        "V88cNuLOSp7e",
        "3cNfm22JTIs9",
        "wUrv-fxXTPWj",
        "4yjhAPTaTYgP",
        "yzijuPO0fkKC",
        "_Qo-uOPBfrje",
        "2hzdweU6Bh7i",
        "-XrzCH4z6_ss",
        "CZOszu8Y7p1k",
        "CNRkgHlk0NBM",
        "NDA2aqmjSGZB",
        "QE3epz7Rbi9y",
        "-qnuEZ4GcDxd",
        "Q9uCc9tKkLdn",
        "OEVh6PirYiA-",
        "ruVRsMvcZjDD",
        "UB-r6sfjBYh9",
        "4XoapvMgZ64I",
        "IOrQOhNq5704",
        "vzOfMvms571G",
        "Wo6s0H6T_8I9",
        "e7MdVauh_8JL",
        "9ss9VFgs_88k",
        "srqqUWsO_88l",
        "eU2JZSlI_88m",
        "kM9bykVw_88n",
        "5jlpvXCoVXQh",
        "MZCCzThWVXQt",
        "sLmHWzu2VXQu",
        "AL4xn0HGVXQu",
        "MIfZY-a7g90Q",
        "xQt89uBIg90Q",
        "20Eaz4iOg90S",
        "FQLz0BdRg90T",
        "CblXIkqOsiqE",
        "NDpwkP6JsiqG",
        "Eerm39iEsiqH",
        "dd32KpnZ5SFx",
        "GrGR3b145SF6",
        "53yoelOq5SF9",
        "sSkUU0KVZ6W5",
        "MK0zK1IZZ6XC",
        "os5YUiTX2UT5",
        "D_AJ5LIz2Vz4",
        "BSVJ0pbN2WNa",
        "NYEqPag02qKZ",
        "e98ZUbZm22OE",
        "Rp2Z5oe7N1M3"
      ],
      "name": "Assignment 6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0564a0534bd348919b2d449d4c75f4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b8cdb85a7a84fbca48633f233bb00df",
              "IPY_MODEL_610f674723db47dfa53dbc08a96cee05",
              "IPY_MODEL_45ca81f6d35f46608cd622a5db8a2dd2"
            ],
            "layout": "IPY_MODEL_7070e68979674461b7640e18d2b7aac4"
          }
        },
        "0807ef1d5bef440eab026169de642297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17d34751168445faa03fdcfeac1eff83",
            "max": 25024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_add0bed843aa4ba8be6f413d7b23a213",
            "value": 25024
          }
        },
        "17d34751168445faa03fdcfeac1eff83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "344f757c297f4dec8643515679b98bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ca81f6d35f46608cd622a5db8a2dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e90162bf3045ccbde21a72b873c1a1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a4314f4295074f809549b59c68841ba5",
            "value": " 12326/12326 [00:01&lt;00:00, 9393.11it/s]"
          }
        },
        "53646c4ab376433a93fd7902a2cc0b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f740669a2ea240c99f187d45e698ae9c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6fbd187abf854d948f3d8af7313c2be6",
            "value": " 25024/25024 [00:03&lt;00:00, 9586.49it/s]"
          }
        },
        "610f674723db47dfa53dbc08a96cee05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_344f757c297f4dec8643515679b98bd7",
            "max": 12326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9189dbddec2457ea52f32f945e3af38",
            "value": 12326
          }
        },
        "65ee1c3638af49b894d3fbce6865cb73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8cdb85a7a84fbca48633f233bb00df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65ee1c3638af49b894d3fbce6865cb73",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ccb6c86d21e6451797ff23f7c60703e5",
            "value": "100%"
          }
        },
        "6fbd187abf854d948f3d8af7313c2be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7070e68979674461b7640e18d2b7aac4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9245a1d13a51458683fb8919859286eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1f9f23283d04df9bab7e503d4a009e2",
              "IPY_MODEL_0807ef1d5bef440eab026169de642297",
              "IPY_MODEL_53646c4ab376433a93fd7902a2cc0b12"
            ],
            "layout": "IPY_MODEL_ba2e795d935147b0b1f35aedc4671d92"
          }
        },
        "95e90162bf3045ccbde21a72b873c1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f9f23283d04df9bab7e503d4a009e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaec8ff6a4664d38b1be547dbb22893f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e43833dbdaf148b19d81bc305daaccf8",
            "value": "100%"
          }
        },
        "a4314f4295074f809549b59c68841ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaec8ff6a4664d38b1be547dbb22893f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add0bed843aa4ba8be6f413d7b23a213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba2e795d935147b0b1f35aedc4671d92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9189dbddec2457ea52f32f945e3af38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccb6c86d21e6451797ff23f7c60703e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e43833dbdaf148b19d81bc305daaccf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f740669a2ea240c99f187d45e698ae9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
